# スプリント3実装計画

**User:** Anonymous (sunpin32@yahoo.co.jp)  
**Created:** 9/8/2025 16:17:26  
**Updated:** 9/9/2025 0:41:44  
**Exported:** 9/9/2025 0:41:55  
**Link:** [https://chatgpt.com/g/g-p-68a2428917408191ab595311b37e4516-itabashi-minutes/c/68be82fe-e1d0-832c-aceb-435dd9a31485](https://chatgpt.com/g/g-p-68a2428917408191ab595311b37e4516-itabashi-minutes/c/68be82fe-e1d0-832c-aceb-435dd9a31485)  

## Response:
思考時間: 38s

問題#33「構造抽出の精度向上（誤検知抑制）」のため、Codexに具体的な指示を作成する必要がある。前のタスクにはAPI、UI、MCP、Nightlyがあり、今回の修正ではagenda項目とスピーカーの抽出改善、正規表現と回帰テスト、精度基準の追加が求められる。モジュールの場所やファイルも仮定しながら。

前回のSprint 2では、正規表現と見出しパターンを使って構造を抽出しました。今回は精度向上を目指し、役職名や委員会名の正規化辞書を追加し、番号付きリストやローマ数字などのパターンも検討。日本語の会議録に合ったサンプルを使い、簡単な正規化マッピングで依存関係を避ける予定です。

実際のPDFファイルはないので、サンプルPDFから抽出した結果を元に小さい合成テストデータを`tests/golden/`に配置するよう指示するつもりです。ただし、大きなファイルは追加できないため、JSON形式で予測される出力を使います。それでも少し複雑なので、既存のテストデータを使って最小限の黄金セットを作成し、パラメータ化されたテキストサンプルでテストを行う方法を提案します。

正規表現の単体テストは作成した入力で実行し、E2EテストではサンプルのNDJSONファイルを使用します。CIではネットワーク取得ができないので、リポジトリ内のサンプル文書に頼ります。もし存在しない場合は、 `tests/fixtures/` に簡易サンプル文書を作成し、役職名や委員会名の正規化などを追加指示する予定です。

完了

了解。#33「構造抽出の精度向上（誤検知抑制）」の **Codex向け実装指示プロンプト** を用意しました。#29〜#32の成果（API/UI/MCP/Nightly）を前提に、抽出ロジックの精度改善＋回帰テスト体制を強化します。

* * *

Codex 実装指示プロンプト（#33 構造抽出の精度向上）
------------------------------

````markdown
# タスク: 構造抽出の精度向上（誤検知抑制／正規化辞書／回帰テスト）

## 目的
- ルールベース抽出（議題・話者）の誤検知を抑制し、Recallを維持しつつ Precision を引き上げる。
- 表記ゆれを正規化する辞書を導入して安定化。
- ゴールデンセットによる回帰テストと簡易メトリクス（Precision/Recall）をCIに組み込む。

## 受入基準（Done）
- `pytest -q` が通過。
- ゴールデンセットで **Precision ≥ 0.90 / Recall ≥ 0.85** を満たす（暫定）。
- 代表的な誤検知パターン（文中の「…について」等）で抽出しない。
- 正規化辞書により、役職・委員会・氏名の表記ゆれが正規形で返る。
- Nightlyの生成物（抽出テキスト経由）にも副作用無し（スキーマ互換）。

## 変更範囲（ファイル）
- **新規** `resources/normalize.yml` … 正規化辞書（役職／委員会／氏名）
- **新規** `ingest/normalize.py` … 正規化ユーティリティ（NFKC＋辞書適用）
- **更新** `ingest/structure_extractor.py` … 見出し・話者の抽出ロジック強化
- **新規** `tests/fixtures/golden/input/*.txt` … 2〜3本の短いサンプル
- **新規** `tests/fixtures/golden/expected/*.json` … 期待値
- **新規** `tests/test_structure_extractor.py` … 単体＋回帰テスト（メトリクス算出）
- **任意** `Makefile` に `make extract-test` を追加（ローカル検証）

> 既存のモジュール名が異なる場合は、近い位置のファイルを検出して同等実装に置き換え可。

---

## 実装詳細

### 1) 正規化辞書 `resources/normalize.yml`
```yaml
roles:
  委員長: [委員長, いんちょう, ○委員長, ◯委員長, ◎委員長]
  委員: [委員, ○委員, ◯委員]
  部長: [部長, ○部長, ◯部長]
  課長: [課長, ○課長, ◯課長]
  議長: [議長, ◎議長]
  理事者: [理事者, 当局, 事務局]
committees:
  文教児童委員会: [文教児童, 文教, 文教・児童]
  企画総務委員会: [企画総務, 総務企画]
  建設環境委員会: [建設環境, 建環]
names:
  # 必要に応じて追加。姓のみでも可。
  中津真穣太: [中津真 穣太, 中津 真穣太, 中津]
options:
  # 大文字小文字・全半角・長音などの正規化オプション
  unify_width: true   # unicodedata.normalize("NFKC")
  strip_spaces: true  # 連続空白・全角空白の圧縮
````

### 2) 正規化ユーティリティ `ingest/normalize.py`

*   `normalize_text(s: str) -> str`：NFKC・空白圧縮・記号のゆらぎ統一（丸印「○/◯/●/◎」→`○`に統一、括弧の全半角統一 等）
*   `normalize_role(s: str) -> str` / `normalize_committee(s: str) -> str` / `normalize_name(s: str) -> str`
    *   `normalize.yml` を読み込み、`aliases -> canonical` へマップ
    *   最長一致／大小無視で置換（辞書に無ければ入力を返す）

### 3) 抽出ロジック `ingest/structure_extractor.py`

*   **前処理（1行化）**：
    *   行末の吊り下げ（句読点でのハードラップ）を吸収：`…。\n` のような「文の途中ではない改行」は維持、語中折返し（`…\n…`）は連結
*   **議題（agenda）抽出**：次のパターンを**行頭アンカー**で検出
    *   `^(議題|案件|議案第[〇一二三四五六七八九十0-9]+号|請願第.+?号|陳情第.+?号|報告事項|所管事務調査)\s*[:：]?\s*(.*)$`
    *   `^議題第[〇一二三四五六七八九十0-9]+\s*[：:]\s*(.*)$`
    *   **否定先読み**：`(?!(について|に関する|の報告))` をタイトル末尾に付与して、文中用法の誤検知を抑制
*   **話者（speaker）抽出**：次の条件で1行目を話者ヘッダとみなす
    *   形式A：`^[○◯◎]?\s*(?P<role>[^：:　 ]{1,12})?\s*(?P<name>[一-龥々ヶ゙゜・\u30A0-\u30FF\u3040-\u309F]{1,12})\s*[：:]`
    *   形式B：`^(?P<role>委員長|委員|部長|課長|理事者|議長|副区長|教育長)\s*(?P<name>[^：:\s　]{1,12})\s*[：:]`
    *   **抑制**：`role+name` 合わせて 2〜20 文字程度、`:` 以降に本文が続くこと、行頭以外に “議題/案件/…について” が無いこと
    *   **同一話者の連結**：次行が無印（ヘッダなし）で始まる場合に前話者に段落追記（空行が来たら話者終了）
*   **正規化の適用**：抽出後に `normalize_*` をかけて正規形に統一
*   **出力**：既存スキーマ（`agenda_items[].title`, `speeches[].role`, `speeches[].speaker`, `speeches[].paragraphs[]`）を維持

> 実装では `re.compile(..., flags=re.MULTILINE)` を使い、パターンはモジュール定数として一箇所にまとめること。否定先読みの有無で Recall が落ちる場合は、辞書化やフォールバック（閾値緩和）を段階的に適用。

### 4) テスト `tests/test_structure_extractor.py`

*   **ユニット**（パラメトリック）
    *   議題見出しの肯定／否定ケース
    *   話者ヘッダ検出（パターンA/B）・同一話者の連結
    *   正規化辞書の適用（役職・委員会・氏名）
*   **ゴールデン**（回帰）
    *   `tests/fixtures/golden/input/*.txt` を読み込み、抽出結果を `expected/*.json` と比較
    *   期待JSONは、議題タイトル配列と話者役職/氏名リストを最低限含める（段落は1,2文程度で十分）
*   **メトリクス**（簡易）
    *   期待値の `set(agenda_titles)`, `set(speakers)` と抽出値を比較し、Precision/Recall を算出
    *   しきい値：Precision ≥ 0.90 / Recall ≥ 0.85（失敗時は diff を表示）

> 外部依存は増やさない。`unicodedata` と `yaml`（PyYAML）が使えれば十分。無ければ最小実装（`safe_load` を想定）。

### 5) Makefile（任意）

```make
extract-test:
\tpytest -q -k "structure_extractor"
```

### 6) ドキュメント

*   `README.md` に「構造抽出の検証方法（extract-test）」と正規化辞書の追記ガイドを追加。
*   誤検知が出たら `resources/normalize.yml` に別名を追加 → テスト追加 → PR。

* * *

実装順（小粒コミット）
-----------

1.  `feat(extract): add normalize.yml & normalize utilities`
2.  `feat(extract): strengthen agenda/speaker patterns and normalization`
3.  `test(extract): golden fixtures & precision/recall assertions`
4.  `docs(extract): README for normalization and verification`
5.  （必要あれば）`chore(make): add extract-test`

注意
--

*   既存スキーマは変更しない（後方互換）。`role/speaker/title` の正規化は値の**正準化**に留める。
*   CIで長大ファイルは避ける。ゴールデンは **短いテキスト** で代表パターンのみ検証。
*   将来のルール調整のため、パターンはモジュール定数＋コメントで出典・意図を明記。

以上の要件で **unified diff** を提示し、PR化してください。

```

---

必要なら、否定先読みの強度を変えた「Recall優先モード」をフラグで切れるようにする追補も書けますが、まずは上記の精度基準で固めましょう。
```



---
Powered by [ChatGPT Exporter](https://www.chatgptexporter.com)